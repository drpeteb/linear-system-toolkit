\documentclass{article}

% Formatting
\usepackage[parfill]{parskip}
\usepackage{geometry}\setlength\textwidth{6in}\setlength\textheight{8.5in}
\usepackage[usenames,dvipsnames]{color}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{bbm}

\usepackage[scaled]{helvet}
\renewcommand*\familydefault{\sfdefault} %% Only if the base font of the document is to be sans serif
\usepackage[T1]{fontenc}

% Environments
\usepackage{IEEEtrantools}
\usepackage{algorithm}
\usepackage{algorithmic}

% References
\usepackage{natbib}%\def\bibfont{\footnotesize}

\newenvironment{review}[0]{\begin{itshape}\color{Gray}\noindent}{\end{itshape}\vspace{0.4cm}}
\newenvironment{response}[0]{\noindent}{\vspace{0.4cm}}
\newcommand{\meta}[1]{{\color{red}\em #1}}

%opening
\title{Bayesian Learning of Degenerate Linear~Gaussian~State~Space~Models using~Markov~Chain~Monte~Carlo \\ Response to Reviews}
\date{January 2016}

\begin{document}

\maketitle

Thank you for taking the time to review our paper. Here is our responses to the points raised.

\meta{
\begin{itemize}
 \item Add trace plots for the transition matrix.
 \item change the observation noise so the rank is not so certain.
 \item Add rank posterior histograms.
 \item leave out parameter conditional moves?
 \item plots
 \item Reviewer 3
 \item Proof read, aiming to (i) clarify (2) correct typos (c) define everything when first used
\end{itemize}

}

\section*{Response to Reviewer 1}

\begin{review}
The paper presents a Bayesian learning method based on Markov Chain Monte Carlo for linear Gaussian state space models. The model may have singular transition covariance matrix. The objective is to infer the unknown states and learn the model parameters given the sequence of observations. Gibbs sampling as well as Metropolis-Hastings methods are utilized.

The reviewer has the following comments:

A main concern is that the paper is not easy to follow. Many statements are mentioned without sufficient or clear justifications. Such as: in Section II.B: ``The appropriate posterior distribution is not amenable to efficient MCMC sampling,...''.
\end{review}

\begin{response}
 We apologise for this. We have looked through and tried to clarify some of what might be the more abstruse portions. In particular, we have re-written that sentence.
\end{response}

\begin{review}
Can the model be extended to the case where the model parameters $H$ and $R$ in (6) are not fixed? Please add discussions.
\end{review}

\begin{response}
 It is straightforward to learn $R$ within the MCMC scheme, and indeed the existing simulations already do precisely this. We have left it out of the algorithm sections to avoid cluttering the presentation. If $H$ were also unknown then there would be problems with identifiability. Most learning algorithms tend to struggle in this case. Fixing $H$ is a design choice, with the appealing property that the components of the latent state can have a meaningful physical interpretation. We have added a discussion of these issues in section II.
\end{response}

\begin{review}
It will be helpful to provide some relevant applications in Section I, explaining why a degenerate model will be more appropriate.
\end{review}

\begin{response}
We have modified the introduction to mention the example of tracking multiple points on a rigid body.
\end{response}

\begin{review}
There is no complexity analysis.
\end{review}

\begin{response}
There is a brief discussion of the computational complexity in the final section of the paper. There is not much to say -- it is of the same order for the full rank and degenerate models but with a higher cost per iteration. We do not see much value in including a detailed operation count, since the dominating factor when considering processing time will be the difference in autocorrelation and the resulting difference in the necessary length of the chain, which will vary by model and data set.
\end{response}

\begin{review}
The advantages over existing methods, such as those methods that use product of marginal distributions or other more recent approaches, have not been adequately demonstrated.
\end{review}

\begin{response}
 As far as we are aware, there are not yet any published algorithms for learning degenerate linear state space models. It would certainly be an interesting project to extend the variational approaches (such as that of Barber \& Chiappa, 2007) to the degenerate case. However, the modifications would be more than trivial, and we feel this would be better suited to some later publication.
\end{response}

\begin{review}
The presentation needs to be improved:
(i) This includes correcting typos, such as: in abstract ``it is possible deduce''
\end{review}

\begin{response}
 We have corrected that typo and a few others which we found.
\end{response}

\begin{review}
(ii) Defining notations before/when using them, such as $F$ and $H$ in equations (1) and (2)
\end{review}

\begin{response}
 We have added or moved a number of definitions, including those for $F$ and $H$.
\end{response}



\section*{Response to Reviewer 2}

\begin{review}
This manuscript studies the problem of Gibbs sampling in the estimation of degenerate linear Gaussian state space model, where the covariance matrix Q of noise in state transition function is singular. This manuscript proposes to decompose matrix Q and convert the problem to a general case conditioned on the known rank $r$ of $Q$. In order to estimate rank $r$, reversible jump MCMC is employed. There are several concerns as follows:

1.  In the manuscript, the authors assume a linear model in which the observation is only determined by the current state. However, in practice, sophisticated models where the observation is also related to the previous states and inputs are more commonly used. So this may limit the applicability of the proposed method.
\end{review}

\begin{response}
 There is a very large body of literature focussed on models where the observation depends only on the current latent state, including most of the papers we have cited. It is usually possible to convert such a non-Markovian model into a Markovian one by augmenting the latent state with additional components. We disagree that this should be considered a limitation of the proposed method.
\end{response}

\begin{review}
2.  It is suggested to introduce some other related works on degenerate linear Gaussian state space model if any.
\end{review}

\begin{response}
 We have added a few references in the introduction to papers which use degenerate linear Gaussian transition models. As far as we are aware, there are not yet any published algorithms for learning degenerate linear state space models.
\end{response}

\begin{review}
3.  The $H$ and $R$ matrices are assumed to be known in the manuscript, which may not be the case in practice. It is suggested to consider the estimation of $H$ and $R$ in the degenerate model.
\end{review}

\begin{response}
 See response to the similar comment by reviewer 1.
\end{response}

\begin{review}
4.  This manuscript uses Givens decomposition to factorize matrix $Q$, and in section III B, it states that matrix $U$ in Givens decomposition is uniquely determined. It should be explained that how to determine matrix $U$ and the necessity of Givens decomposition.
\end{review}

\begin{response}
 We have added more explanation of the Givens decomposition, and also algorithm pseudo-code for its calculation.
\end{response}

\begin{review}
5.   The first step of Gibbs sampling in linear state space model is the estimation of states $x$ from observation $y$. It should be clarified that whether the singularity of matrix $Q$ will have any effect on this estimation. 
\end{review}

\begin{response}
 The procedure for sampling the state trajectories is unchanged by the singularity of $Q$. We have noted this in the text and also added a short appendix discussing this point and providing the equations for the forward-filtering-backward-sampling algorithm.
\end{response}

\begin{review}
6.  It should be explained that how the probabilities of $P(r \to r+1)$ and $P(r+1 \to r)$ in Eq.(59) are determined in simulations.
\end{review}

\begin{response}
 These two probabilities are design parameters. We have clarified this and added their values to the simulations section.
\end{response}

\begin{review}
7.  In simulations, the Metropolis-Hastings step should also be applied to the full rank linear model if not.
\end{review}

\begin{response}
This comment is not entirely clear to us. We could indeed apply the random walk MH steps to the full rank model, but what would be the point? These steps are essential only in the degenerate case to ensure the reducibility of the Markov chain. The mixing due to the MH steps is much slower than that due to the Gibbs steps, so including them in the full rank algorithm has a negligible effect on the autocorrelation.
\end{response}

\begin{review}
8.  In eq. (24), function $exp()$ should be replaced by $exp(tr())$. In line 38 page 10, the first 'is' should be deleted.
\end{review}

\begin{response}
 We have corrected these two typos.
\end{response}

\begin{review}
I suggest the authors to address these problems and to submit it to IEEE Signal Processing Letters or do a resubmission.
\end{review}

\begin{response}
 We considered submitting this as a letters paper but we do not believe it meets, or could be made to meet, the requirements for either length or content.
\end{response}


\section*{Response to Reviewer 3}

\begin{review}
In this paper, the authors address the Bayesian learning of degenerate linear and Gaussian state space models. In this specific context, classical Gibbs sampler can not be used and therefore the authors propose an interesting and complete framework based on Markov Chain Monte Carlo (MCMC) to deal with this challenging problem. The paper is well written and organized. I have the following remarks:

Even if I found the paper well organized, I think that the authors should summarize the complete framework (RJ-MCMC) in an algorithm - in my opinion it will help the reader to understand it by summarizing all the steps of the proposed scheme in one place.
\end{review}

\begin{response}
 A good point. We have added algorithm pseudo-code describing the steps of the complete MCMC kernel. It was an oversight to leave this out.
\end{response}

\begin{review}
In Section III-C, the authors propose to use a collapsed Gibbs move to more efficiently exploit the target on the space of $F$ and $Q$, alternatively. I think the authors should discuss in more details why such collapsed Gibbs is important in the text. Moreover, the importance of such steps could be easily illustrated in the results section so the reader can appreciate the benefit of using such a strategy.
\end{review}

\begin{response}
 There is a misunderstanding here, probably due to the confusing terminology. The ``collapsed Gibbs move'' simply means the composition of first targeting $\pi(F, Q)$ with Metropolis-Hastings followed by a draw from $\pi(x_{1:T}|F, Q)$. These moves are essential for the sampler to be irreducible, and they are woefully inefficient. To speed things up, we also include exact draws from the the parameter conditional $\pi(F, Q|x_{1:T})$. These are inspired by the Gibbs sampler for the full rank algorithm, but cannot fully explore the parameter space, so we refer to them as constrained Gibbs moves.
 
 It does not make sense to run the sampler without the Metropolis-Hastings/constrained-Gibbs moves. It will be stuck in whatever subspace we happen to initialise it in. We {\em could} run it without the draws from the parameter conditional, but our python implementation would take literally years to converge.
 
 We have substantially re-arranged section III and added further explanation of these concepts. We hope it is clearer now.
\end{response}

\begin{review}
My main concern is regarding the simulation section.

Firstly, the comments are just a brief summary of results from the figures without any comments or discussions on why such results are obtained.
\end{review}

\begin{response}
 \meta{Add more discussion and analysis}
\end{response}

\begin{review}
There are no figures that show the evolution of the Markov chain OR the posterior approximation of the unknown rank $r$
The authors wrote that ``the sampler identifies the true rank.... and remains at this value thereafter'' but this can be worrying - this statement could also mean that the sampler is not mixing properly for this variable $r$. The author should be more precised by saying ``Trace plots suggest that the sampler converges within a few thousand iterations. See figure 2'' - The convergence showed in this figure is only related to the variable $\xi_y$.
\end{review}

\begin{response}
 \meta{Explain this and improve in the paper. Add simple example of changing rank to show that it is not stuck.}
\end{response}

\begin{review}
The authors could illustrate in the first toy example the benefit of the collapsed Gibbs
moves by showing the performance of the sampler with vs without this strategy.
\end{review}

\begin{response}
 \meta{Try running without parameter conditional draws on toy model. Very slow, right?!}
\end{response}

\begin{review}
I personally think that the proposed algorithm should be illustrated with at least a different set of parameters for the toy example (e.g. different values for $\xi_y$ thus allowing to have a curve of RMSE vs $\xi_y$ )
\end{review}

\begin{response}
 \meta{Ok... if it will make you happy. Obviously it will work for some parameters and not others.}
\end{response}

\begin{review}
List of minor remarks/typos:

Just after Eq. (16), the authors should be more precise on the following sentence to avoid any confusion: ``However, whereas before $Q$ was required to be positive definite, this is no longer the case'' (I would add) for unknown $G$.
\end{review}

\begin{response}
 We have re-written this sentence. 
\end{response}

\begin{review}
Please correct in Section V first sentence ... known a prior. by ... known a priori.
\end{review}

\begin{response}
This has been corrected.
\end{response}


\end{document}
